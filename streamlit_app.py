import streamlit as st
from openai import OpenAI

# ì§€ì—­ëª… ë¦¬ìŠ¤íŠ¸ (í•„ìš”ì‹œ ì¶”ê°€ ê°€ëŠ¥)
known_regions = ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ëŒ€ì „", "ê´‘ì£¼", "ì¸ì²œ", "ì œì£¼", "ìˆ˜ì›", "ìš¸ì‚°", "ì¶˜ì²œ"]

def extract_region(prompt):
    for region in known_regions:
        if region in prompt:
            return region
    return None

st.title("ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ ê°€ì¡± ë‚˜ë“¤ì´ ì¥ì†Œ ì¶”ì²œ ì±—ë´‡")
st.write("ì§€ì—­ëª…ì„ ì…ë ¥í•˜ë©´, GPTê°€ ê·¸ ì§€ì—­ì—ì„œ ê°€ì¡±ì´ ë†€ê¸° ì¢‹ì€ ì¥ì†Œë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì²œí•´ì¤˜ìš”!")

openai_api_key = st.text_input("OpenAI API Key", type="password")
if not openai_api_key:
    st.info("Please add your OpenAI API key to continue.", icon="ğŸ—ï¸")
else:
    client = OpenAI(api_key=openai_api_key)

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("ì–´ë””ë¡œ ë‚˜ë“¤ì´ ê°€ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"):

        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        region = extract_region(prompt)
        if region:
            auto_prompt = f"{region}ì—ì„œ ê°€ì¡±ì´ í•¨ê»˜ ë†€ê¸° ì¢‹ì€ ì¥ì†Œ 3ê³³ì„ ì¶”ì²œí•´ì¤˜. ì¥ì†Œ ì´ë¦„ê³¼ ê°„ë‹¨í•œ ì„¤ëª…ë„ í¬í•¨í•´ì¤˜."
            full_messages = [{"role": "system", "content": "ë„ˆëŠ” ì—¬í–‰ì§€ ì¶”ì²œ ì „ë¬¸ê°€ì•¼. ì¥ì†Œ ì¶”ì²œë§Œ ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ í•´ì¤˜."}]
            full_messages += [{"role": "user", "content": auto_prompt}]
        else:
            full_messages = [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]

        stream = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=full_messages,
            stream=True,
        )

        with st.chat_message("assistant"):
            response = st.write_stream(stream)
        st.session_state.messages.append({"role": "assistant", "content": response})
